
# âš¡ Energy-Efficient AI with CNN Compression

This project explores **energy-efficient neural network compression techniques** for deep learning models, with a focus on **ResNet-18** trained on **CIFAR-10**.  
We implement **Pruning, Quantization, and Knowledge Distillation**, benchmark trade-offs (accuracy vs size vs latency vs throughput), and provide a **Streamlit UI** for interactive exploration.  

---

## ğŸ“Œ Features
- âœ… **Baseline Training**: Train ResNet-18 on CIFAR-10.  
- âœ… **Structured Pruning**: Remove redundant channels for efficiency.  
- âœ… **Quantization**: Convert FP32 â†’ INT8 for faster inference.  
- âœ… **Knowledge Distillation**: Transfer knowledge from ResNet-18 (teacher) â†’ MobileNetV2 (student).  
- âœ… **Benchmarking**: Compare accuracy, latency, size, and throughput.  
- âœ… **Interactive UI**: Upload/test images, visualize predictions, and compare models.  

---

## ğŸ“‚ Project Structure
```
Energy-Efficient-AI-with-CNN-Compression/
â”‚â”€â”€ demo/                 # Streamlit UI
â”‚   â””â”€â”€ app.py
â”‚â”€â”€ pipelines/            # Training & compression pipelines
â”‚   â”œâ”€â”€ train_baseline.py
â”‚   â”œâ”€â”€ prune_structured.py
â”‚   â”œâ”€â”€ quantize_dynamic.py
â”‚   â”œâ”€â”€ distill.py
â”‚   â””â”€â”€ benchmark.py
â”‚â”€â”€ models/               # CNN model definitions
â”‚   â”œâ”€â”€ resnet18.py
â”‚   â””â”€â”€ mobilenetv2.py
â”‚â”€â”€ utils/                # Helpers (data loaders, training loop, etc.)
â”‚â”€â”€ artifacts/            # Trained & compressed models (.pt files)
â”‚â”€â”€ reports/              # Benchmark results (CSV, charts)
â”‚â”€â”€ prepare_data.py       # Download CIFAR-10 dataset
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
```

---

## âš™ï¸ Installation

### Step 1: Clone Repo
```bash
git clone https://github.com/iashokk/Energy-Efficient-AI-with-CNN-Compression.git
cd Energy-Efficient-AI-with-CNN-Compression
```

### Step 2: Create Virtual Environment
```bash
python -m venv .venv
# Activate it
.venv\Scripts\activate       # Windows
source .venv/bin/activate    # Linux/Mac
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Download CIFAR-10 Dataset
```bash
python prepare_data.py
```

---

## ğŸš€ Usage

### 1. Train Baseline ResNet-18
```bash
python -m pipelines.train_baseline --dataset cifar10 --model resnet18 --epochs 30 --bs 128 --lr 0.001
```

### 2. Apply Structured Pruning
```bash
python -m pipelines.prune_structured --dataset cifar10 --model resnet18 --sparsity 0.5 --finetune-epochs 8 --ckpt artifacts/resnet18_best.pt
```

### 3. Apply Dynamic Quantization
```bash
python -m pipelines.quantize_int8 --ckpt artifacts/resnet18_best.pt
```

### 4. Knowledge Distillation (ResNet18 â†’ MobileNetV2)
```bash
python -m pipelines.distill_kd --teacher resnet18 --student mobilenetv2 --epochs 20
```

### 5. Benchmark All Models
```bash
python -m pipelines.benchmark --dataset cifar10 --device cpu --repeat 500     --models artifacts/resnet18_best.pt artifacts/pruned_resnet18.pt artifacts/quantized_resnet18.pt artifacts/kd_mobilenetv2.pt
```

### 6. Run Streamlit UI
```bash
streamlit run demo/app.py
```

---

## ğŸ“Š Sample Results

| Model              | Accuracy (%) | Size (MB) | Latency (ms) | Throughput (img/s) |
|--------------------|-------------:|----------:|-------------:|-------------------:|
| ResNet18           | 76.9         | 42.7      | 17.8         | 56.3               |
| Pruned ResNet18    | 79.0         | 42.7      | 18.4         | 54.1               |
| Quantized ResNet18 | 76.9         | 42.7      | 15.8         | 63.0               |
| KD MobileNetV2     | 73.6         | 8.8       | 26.2         | 38.2               |

---

## ğŸ–¼ï¸ Screenshots (Placeholders)

### Streamlit Dashboard
![UI Screenshot](reports/ui_demo.png)

### Benchmark Comparison
![Benchmark Chart](reports/benchmark_plot.png)

---

## ğŸ“Œ Future Work
- Structured pruning with **torch-pruning** for actual size reduction.  
- Energy & COâ‚‚ tracking with **CodeCarbon**.  
- Grad-CAM visualizations for interpretability.  
- Deployment with **ONNX/TorchScript** + Docker.  
- Gemini AI integration for **Auto-Documentation** & **Carbon Footprint Narration**.  

---

## ğŸ‘¨â€ğŸ’» Authors
- **Ashok** â€“ Project Lead  
- (Contributors welcome via PRs)
